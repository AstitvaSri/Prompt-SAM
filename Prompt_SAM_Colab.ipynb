{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run this cell to set up SAM\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!{sys.executable} -m pip install gradio\n",
        "!{sys.executable} -m pip install open_clip_torch\n",
        "\n",
        "!wget https://raw.githubusercontent.com/AstitvaSri/Prompt-SAM/main/prompt_masks.py\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "# def get_masked_images(img,MAX_NUM_MASK):\n",
        "#   masks = mask_generator.generate(img)\n",
        "#   masked_images = []\n",
        "#   for mask in masks[:MAX_NUM_MASK]:\n",
        "#     temp_img = deepcopy(img)\n",
        "#     temp_mask = mask['segmentation']\n",
        "#     temp_img[temp_mask == False] = [255,255,255]\n",
        "#     masked_images.append(temp_img)\n",
        "#   return masked_images"
      ],
      "metadata": {
        "id": "F6BxQEcuk_mL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Run this cell to set up CLIP\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import open_clip\n",
        "\n",
        "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
        "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n"
      ],
      "metadata": {
        "id": "F5dwXxSLk-tM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Run this cell for GRADIO demo --> Input text and get corresponding masks\n",
        "\n",
        "from prompt_masks import PromptSAM\n",
        "\n",
        "maximum_number_of_masks = \"50\" \n",
        "\n",
        "psam = PromptSAM(int(maximum_number_of_masks))\n",
        "psam.config(model, tokenizer, preprocess, mask_generator)\n",
        "\n",
        "with gr.Blocks() as grdemo:\n",
        "  with gr.Row():\n",
        "    uploadgr = gr.Interface(fn=psam.upload_image, inputs=[\"image\"], outputs=\"text\", allow_flagging=\"never\", show_progress=True)\n",
        "    interfacegr = gr.Interface(fn=psam.prompt_sam, inputs=[\"text\"], outputs=\"image\", allow_flagging=\"never\")\n",
        "grdemo.queue().launch(debug=True)"
      ],
      "metadata": {
        "id": "CAi9akAujt41",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}